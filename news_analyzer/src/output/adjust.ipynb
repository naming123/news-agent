{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "972c921f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "복사 계획:\n",
      "  - output: dst_row=857842, src_row=1, rows=190735\n",
      "  - output_2: dst_row=1, src_row=190736, rows=96739\n",
      "완료: 1003.xlsx\n"
     ]
    }
   ],
   "source": [
    "# 01_move_sheet1_to_outputs.py\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# ===== 설정 =====\n",
    "FILE_PATH      = \"1003.xlsx\"\n",
    "SRC_SHEET      = \"Sheet1\"\n",
    "DST_BASE       = \"output\"\n",
    "SRC_START_COL  = 2           # Sheet1에서 B열부터 복사\n",
    "DST_START_ROW  = 857_842     # output에서 시작 행\n",
    "DST_START_COL  = 2           # output에서 B열부터\n",
    "EXCEL_MAX_ROWS = 1_048_576\n",
    "EXCEL_MAX_COLS = 16_384\n",
    "# =================\n",
    "\n",
    "def main():\n",
    "    wb = load_workbook(FILE_PATH)\n",
    "    if SRC_SHEET not in wb.sheetnames:\n",
    "        raise ValueError(f\"시트 없음: {SRC_SHEET}\")\n",
    "    if DST_BASE not in wb.sheetnames:\n",
    "        raise ValueError(f\"시트 없음: {DST_BASE}\")\n",
    "\n",
    "    ws_src = wb[SRC_SHEET]\n",
    "    max_row = ws_src.max_row\n",
    "    max_col = ws_src.max_column\n",
    "\n",
    "    # 열 한도 체크\n",
    "    needed_cols = DST_START_COL + (max_col - SRC_START_COL)\n",
    "    if needed_cols > EXCEL_MAX_COLS:\n",
    "        raise ValueError(f\"붙여넣기 후 열({needed_cols})이 엑셀 최대({EXCEL_MAX_COLS})를 초과합니다.\")\n",
    "\n",
    "    # 복사할 총 행 수 (헤더 포함 전체)\n",
    "    remain = max_row\n",
    "    src_row_ptr = 1\n",
    "\n",
    "    # 1) 첫 대상 시트: output 의 지정 시작행부터 가능한 만큼\n",
    "    plans = []  # [(sheet_name, dst_row_start, src_row_start, rows)]\n",
    "    room_first = EXCEL_MAX_ROWS - DST_START_ROW + 1\n",
    "    use_first = max(0, min(remain, room_first))\n",
    "    if use_first > 0:\n",
    "        plans.append((DST_BASE, DST_START_ROW, src_row_ptr, use_first))\n",
    "        remain      -= use_first\n",
    "        src_row_ptr += use_first\n",
    "\n",
    "    # 2) 넘치는 건 output_2, output_3 ... 로 1행부터 이어붙이기\n",
    "    idx = 2\n",
    "    while remain > 0:\n",
    "        name = f\"{DST_BASE}_{idx}\"\n",
    "        if name not in wb.sheetnames:\n",
    "            wb.create_sheet(name)\n",
    "        use = min(remain, EXCEL_MAX_ROWS)\n",
    "        plans.append((name, 1, src_row_ptr, use))\n",
    "        remain      -= use\n",
    "        src_row_ptr += use\n",
    "        idx         += 1\n",
    "\n",
    "    # 실행\n",
    "    for sheet_name, dst_row0, src_row0, rows in plans:\n",
    "        ws_dst = wb[sheet_name]\n",
    "        for dr in range(rows):  # 0..rows-1\n",
    "            r_src = src_row0 + dr\n",
    "            r_dst = dst_row0 + dr\n",
    "            for c in range(SRC_START_COL, max_col + 1):\n",
    "                ws_dst.cell(\n",
    "                    row=r_dst,\n",
    "                    column=DST_START_COL + (c - SRC_START_COL),\n",
    "                    value=ws_src.cell(row=r_src, column=c).value\n",
    "                )\n",
    "\n",
    "    wb.save(FILE_PATH)  # 같은 파일에 반영 (원하면 다른 이름으로 저장)\n",
    "    wb.close()\n",
    "\n",
    "    print(\"복사 계획:\")\n",
    "    for s, drow, srow, rows in plans:\n",
    "        print(f\"  - {s}: dst_row={drow}, src_row={srow}, rows={rows}\")\n",
    "    print(f\"완료: {FILE_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe16518b",
   "metadata": {},
   "source": [
    "### 30일 룰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66abbc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_26744\\1357784805.py:70: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = work.groupby([\"__kw\", \"__co\"], group_keys=False).apply(keep_rule)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30일 규칙: 496763 → 192944행 저장 → dedup_30d.xlsx\n"
     ]
    }
   ],
   "source": [
    "# 02_dedup_30days_from_outputs.py\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "FILE_PATH   = \"1003.xlsx\"             # 원본 파일에서 output* 읽음\n",
    "SHEET_PATT  = r\"^output(_\\d+)?$\"\n",
    "OUT_PATH    = \"dedup_30d.xlsx\"\n",
    "BASE_SHEET  = \"dedup_30d\"\n",
    "\n",
    "KW_COL = \"뉴스 키워드 후보\"\n",
    "CO_COL = \"회사명\"\n",
    "DT_COL = \"뉴스 보도날짜(YYYYMMDD)\"\n",
    "URL_COL = \"URL\"   # 있으면\n",
    "\n",
    "WINDOW_DAYS = 30\n",
    "EXCEL_MAX_ROWS = 1_048_576\n",
    "\n",
    "def write_split(df: pd.DataFrame, path: str, base: str):\n",
    "    with pd.ExcelWriter(path, engine=\"openpyxl\") as w:\n",
    "        if len(df) == 0:\n",
    "            df.head(0).to_excel(w, index=False, sheet_name=base)\n",
    "            return\n",
    "        start, part = 0, 1\n",
    "        while start < len(df):\n",
    "            end  = min(start + EXCEL_MAX_ROWS - 1, len(df))\n",
    "            name = base if part == 1 else f\"{base}_{part}\"\n",
    "            df.iloc[start:end].to_excel(w, index=False, sheet_name=name)\n",
    "            start = end\n",
    "            part += 1\n",
    "\n",
    "def main():\n",
    "    xl = pd.ExcelFile(FILE_PATH)\n",
    "    sheets = [s for s in xl.sheet_names if re.match(SHEET_PATT, s)]\n",
    "    if not sheets:\n",
    "        raise ValueError(\"output / output_2 ... 시트를 찾지 못했습니다.\")\n",
    "\n",
    "    frames = [pd.read_excel(FILE_PATH, sheet_name=s, dtype=str) for s in sheets]\n",
    "    df = pd.concat(frames, ignore_index=True)\n",
    "    df = df.rename(columns=lambda x: str(x).strip())\n",
    "\n",
    "    # 필수 컬럼 체크\n",
    "    for col in [KW_COL, CO_COL, DT_COL]:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"필수 열 누락: {col} (D=뉴스 키워드 후보, K=회사, G=YYYYMMDD)\")\n",
    "\n",
    "    work = df.copy()\n",
    "    work[\"__kw\"] = work[KW_COL].fillna(\"\").str.strip().str.lower()\n",
    "    work[\"__co\"] = work[CO_COL].fillna(\"\").str.strip().str.lower()\n",
    "    work[\"__date\"] = pd.to_datetime(work[DT_COL].astype(str).str.strip(),\n",
    "                                    format=\"%Y%m%d\", errors=\"coerce\")\n",
    "\n",
    "    # 완전 중복(키·회사·날짜·URL) 제거\n",
    "    subset = [\"__kw\", \"__co\", \"__date\"]\n",
    "    if URL_COL in work.columns:\n",
    "        subset.append(URL_COL)\n",
    "    work = work.drop_duplicates(subset=subset, keep=\"first\")\n",
    "\n",
    "    work = work.sort_values([\"__kw\", \"__co\", \"__date\"], kind=\"stable\")\n",
    "\n",
    "    def keep_rule(g: pd.DataFrame) -> pd.DataFrame:\n",
    "        keep_idx, last = [], pd.Timestamp.min\n",
    "        for idx, row in g.iterrows():\n",
    "            d = row[\"__date\"]\n",
    "            if pd.isna(d):  # 날짜 없으면 유지(필요하면 제외로 변경)\n",
    "                keep_idx.append(idx); continue\n",
    "            if d >= last + pd.Timedelta(days=WINDOW_DAYS):\n",
    "                keep_idx.append(idx); last = d\n",
    "        return g.loc[keep_idx]\n",
    "\n",
    "    out = work.groupby([\"__kw\", \"__co\"], group_keys=False).apply(keep_rule)\n",
    "    out = out.drop(columns=[\"__kw\", \"__co\", \"__date\"]).reset_index(drop=True)\n",
    "\n",
    "    write_split(out, OUT_PATH, BASE_SHEET)\n",
    "    print(f\"30일 규칙: {len(work)} → {len(out)}행 저장 → {OUT_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9459e1e",
   "metadata": {},
   "source": [
    "#### (데코 평산 국제개발 도움 우방 우영 부흥 세신 자강) 제거 및 [Who is ?]로 시작하는 기사 없애기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad0d0fc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "property 'book' of 'OpenpyxlWriter' object has no setter",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 105\u001b[39m\n\u001b[32m    102\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m같은 파일에 시트 추가 완료 → \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mIN_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 93\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m# 5) 같은 파일에 \"시트 추가\"로 저장\u001b[39;00m\n\u001b[32m     92\u001b[39m wb = load_workbook(IN_PATH)  \u001b[38;5;66;03m# 기존 워크북 로드\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[43mwrite_split_append\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkept\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                 \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdedup_30d_kept\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m write_split_append(wb, removed_by_company,   \u001b[33m\"\u001b[39m\u001b[33mdedup_30d_removed\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     95\u001b[39m write_split_append(wb, kept_clean,           \u001b[33m\"\u001b[39m\u001b[33mdedup_30d_kept_clean\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mwrite_split_append\u001b[39m\u001b[34m(wb, df, base)\u001b[39m\n\u001b[32m     38\u001b[39m existing = \u001b[38;5;28mset\u001b[39m(wb.sheetnames)\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pd.ExcelWriter(IN_PATH, engine=\u001b[33m\"\u001b[39m\u001b[33mopenpyxl\u001b[39m\u001b[33m\"\u001b[39m, mode=\u001b[33m\"\u001b[39m\u001b[33ma\u001b[39m\u001b[33m\"\u001b[39m, if_sheet_exists=\u001b[33m\"\u001b[39m\u001b[33moverlay\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[43mwriter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbook\u001b[49m = wb\n\u001b[32m     41\u001b[39m     writer.sheets = {ws.title: ws \u001b[38;5;28;01mfor\u001b[39;00m ws \u001b[38;5;129;01min\u001b[39;00m wb.worksheets}\n\u001b[32m     43\u001b[39m     n = \u001b[38;5;28mlen\u001b[39m(df)\n",
      "\u001b[31mAttributeError\u001b[39m: property 'book' of 'OpenpyxlWriter' object has no setter"
     ]
    }
   ],
   "source": [
    "# 04_append_cleaned_sheets_into_same_file.py\n",
    "import re\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "IN_PATH     = \"dedup_30d.xlsx\"            # 기존 파일에 \"시트 추가\"로 저장\n",
    "SHEET_PATT  = r\"^dedup_30d(_\\d+)?$\"\n",
    "\n",
    "# 컬럼명\n",
    "KW_COL  = \"뉴스 키워드 후보\"\n",
    "CO_COL  = \"회사명\"\n",
    "DT_COL  = \"뉴스 보도날짜(YYYYMMDD)\"\n",
    "URL_COL = \"URL\"  # 없어도 됨\n",
    "\n",
    "# 제외(블랙리스트) 회사명 (정확히 일치)\n",
    "BLACKLIST = {\"데코\", \"평산\", \"국제개발\", \"도움\", \"우방\", \"우영\", \"부흥\", \"세신\", \"자강\", \"대국\"}\n",
    "\n",
    "EXCEL_MAX_ROWS = 1_048_576\n",
    "\n",
    "def unique_sheet_name(existing: set, base: str) -> str:\n",
    "    \"\"\"기존 시트 목록과 충돌하지 않게 고유한 시트명 생성.\"\"\"\n",
    "    if base not in existing:\n",
    "        existing.add(base)\n",
    "        return base\n",
    "    i = 2\n",
    "    while True:\n",
    "        cand = f\"{base}_{i}\"\n",
    "        if cand not in existing:\n",
    "            existing.add(cand)\n",
    "            return cand\n",
    "        i += 1\n",
    "\n",
    "def write_split_append(wb, df: pd.DataFrame, base: str):\n",
    "    \"\"\"\n",
    "    같은 파일(워크북)에 시트를 '추가'로 기록.\n",
    "    행이 많으면 base, base_2, base_3 ... 로 분할 저장.\n",
    "    \"\"\"\n",
    "    existing = set(wb.sheetnames)\n",
    "    with pd.ExcelWriter(IN_PATH, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"overlay\") as writer:\n",
    "        writer.book = wb\n",
    "        writer.sheets = {ws.title: ws for ws in wb.worksheets}\n",
    "\n",
    "        n = len(df)\n",
    "        if n == 0:\n",
    "            name = unique_sheet_name(existing, base)\n",
    "            df.head(0).to_excel(writer, index=False, sheet_name=name)\n",
    "            return\n",
    "\n",
    "        start = 0\n",
    "        part  = 1\n",
    "        while start < n:\n",
    "            end  = min(start + EXCEL_MAX_ROWS - 1, n)\n",
    "            name = unique_sheet_name(existing, base if part == 1 else f\"{base}_{part}\")\n",
    "            df.iloc[start:end].to_excel(writer, index=False, sheet_name=name)\n",
    "            start = end\n",
    "            part += 1\n",
    "\n",
    "def get_h_colname(df: pd.DataFrame) -> str:\n",
    "    \"\"\"H열(8번째, 0-based 7)의 실제 컬럼명 반환.\"\"\"\n",
    "    if df.shape[1] < 8:\n",
    "        raise ValueError(f\"H열을 찾을 수 없습니다. (열 개수 {df.shape[1]} < 8)\")\n",
    "    return df.columns[7]\n",
    "\n",
    "def main():\n",
    "    # 1) 원본 시트들 읽기\n",
    "    xl = pd.ExcelFile(IN_PATH)\n",
    "    sheets = [s for s in xl.sheet_names if re.match(SHEET_PATT, s)]\n",
    "    if not sheets:\n",
    "        raise ValueError(\"dedup_30d / dedup_30d_2 ... 시트를 찾지 못했습니다.\")\n",
    "    frames = [pd.read_excel(IN_PATH, sheet_name=s, dtype=str) for s in sheets]\n",
    "    df = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "    # 2) 컬럼명 트림 + 필수 컬럼 검사\n",
    "    df = df.rename(columns=lambda x: str(x).strip())\n",
    "    for col in [KW_COL, CO_COL, DT_COL]:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"필수 열 누락: {col}\")\n",
    "\n",
    "    # 3) 블랙리스트 분리\n",
    "    co_norm = df[CO_COL].fillna(\"\").str.strip()\n",
    "    is_removed = co_norm.isin(BLACKLIST)\n",
    "    removed_by_company = df.loc[is_removed].copy()\n",
    "    kept = df.loc[~is_removed].copy()\n",
    "\n",
    "    # 4) kept에서 H열 \"[Who is ?]\" 시작 분리\n",
    "    h_col = get_h_colname(kept)\n",
    "    whois_mask = kept[h_col].fillna(\"\").str.strip().str.startswith(\"[Who is ?]\")\n",
    "    kept_clean = kept.loc[~whois_mask].copy()\n",
    "    kept_whois_removed = kept.loc[whois_mask].copy()\n",
    "\n",
    "    # 5) 같은 파일에 \"시트 추가\"로 저장\n",
    "    wb = load_workbook(IN_PATH)  # 기존 워크북 로드\n",
    "    write_split_append(wb, kept,                 \"dedup_30d_kept\")\n",
    "    write_split_append(wb, removed_by_company,   \"dedup_30d_removed\")\n",
    "    write_split_append(wb, kept_clean,           \"dedup_30d_kept_clean\")\n",
    "    write_split_append(wb, kept_whois_removed,   \"dedup_30d_kept_whois_removed\")\n",
    "    wb.save(IN_PATH)\n",
    "    wb.close()\n",
    "\n",
    "    print(f\"총 {len(df)}행 → 블랙리스트 제외 {len(removed_by_company)}행, 남김 {len(kept)}행\")\n",
    "    print(f\"kept 중 H열 '[Who is ?]' 시작 제외 {len(kept_whois_removed)}행, 최종 {len(kept_clean)}행\")\n",
    "    print(f\"같은 파일에 시트 추가 완료 → {IN_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814716f0",
   "metadata": {},
   "source": [
    "### 월 하나씩만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7fe385",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'G'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\yalco-Docker\\data_project\\data_venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3801\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3802\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3803\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:153\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:182\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'G'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 61\u001b[39m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m월 1건: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(work)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m → \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(out)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m행 저장 → \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUT_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     35\u001b[39m df = pd.concat(frames, ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     37\u001b[39m work = df.copy()\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m work[\u001b[33m\"\u001b[39m\u001b[33m__date\u001b[39m\u001b[33m\"\u001b[39m] = pd.to_datetime(\u001b[43mwork\u001b[49m\u001b[43m[\u001b[49m\u001b[43mDT_COL\u001b[49m\u001b[43m]\u001b[49m.astype(\u001b[38;5;28mstr\u001b[39m).str.strip(),\n\u001b[32m     39\u001b[39m                                 \u001b[38;5;28mformat\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m\"\u001b[39m, errors=\u001b[33m\"\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# 완전 중복 제거\u001b[39;00m\n\u001b[32m     42\u001b[39m subset = [KW_COL, CO_COL, \u001b[33m\"\u001b[39m\u001b[33m__date\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\yalco-Docker\\data_project\\data_venv\\Lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4088\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4089\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4090\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4091\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4092\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\yalco-Docker\\data_project\\data_venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3809\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3805\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3806\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3807\u001b[39m     ):\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3809\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3810\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3811\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3812\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3813\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'G'"
     ]
    }
   ],
   "source": [
    "# 03_pick_monthly_one_from_outputs.py  (월(MM) 기준 (키워드,회사) 월 1건)\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "IN_PATH     = \"1003.xlsx\"                 # 입력 엑셀\n",
    "SHEET_PATT  = r\"^output(_\\d+)?$\"          # output, output_2, output_3 ... 전부 읽기\n",
    "OUT_PATH    = \"monthly_one.xlsx\"          # 결과 파일\n",
    "BASE_SHEET  = \"monthly_one\"               # 결과 시트(여러 개로 분할 저장될 수 있음)\n",
    "EXCEL_MAX_ROWS = 1_048_576\n",
    "\n",
    "KW_COL = \"뉴스 키워드 후보\"\n",
    "CO_COL = \"회사명\"\n",
    "DT_COL = \"뉴스 보도날짜(YYYYMMDD)\"\n",
    "URL_COL = \"URL\"   # 있으면\n",
    "\n",
    "# 폴백: 엑셀 열 위치 (0-based index)  D=3, G=6, K=10, J=9\n",
    "FALLBACK_POS = {\"KW\": 3, \"DT\": 6, \"CO\": 10, \"URL\": 9}\n",
    "\n",
    "def resolve_col(df: pd.DataFrame, preferred: str, fallback_idx: int) -> str:\n",
    "    \"\"\"컬럼명이 preferred면 그대로, 없으면 열 위치로 폴백하여 실제 df 컬럼명을 반환.\"\"\"\n",
    "    cols = list(df.columns)\n",
    "    if preferred in cols:\n",
    "        return preferred\n",
    "    if 0 <= fallback_idx < len(cols):\n",
    "        return cols[fallback_idx]\n",
    "    raise KeyError(f\"컬럼 해석 실패: '{preferred}'도 없고, 인덱스 {fallback_idx}도 범위를 벗어남. cols={cols}\")\n",
    "\n",
    "def write_split(df: pd.DataFrame, path: str, base: str):\n",
    "    with pd.ExcelWriter(path, engine=\"openpyxl\") as w:\n",
    "        if len(df) == 0:\n",
    "            df.head(0).to_excel(w, index=False, sheet_name=base); return\n",
    "        start, part = 0, 1\n",
    "        while start < len(df):\n",
    "            end  = min(start + EXCEL_MAX_ROWS - 1, len(df))\n",
    "            name = base if part == 1 else f\"{base}_{part}\"\n",
    "            df.iloc[start:end].to_excel(w, index=False, sheet_name=name)\n",
    "            start = end; part += 1\n",
    "\n",
    "def main():\n",
    "    # 1) output, output_2 ... 시트 모아 읽기\n",
    "    xl = pd.ExcelFile(IN_PATH)\n",
    "    sheets = [s for s in xl.sheet_names if re.match(SHEET_PATT, s)]\n",
    "    if not sheets:\n",
    "        raise ValueError(\"output / output_2 ... 시트를 찾지 못했습니다.\")\n",
    "\n",
    "    frames = [pd.read_excel(IN_PATH, sheet_name=s, dtype=str) for s in sheets]\n",
    "    df = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "    # 2) 컬럼명 해석 (한글 헤더 우선, 없으면 D/G/K/J 위치로 폴백)\n",
    "    KW_COL  = resolve_col(df, PREF_KW,  FALLBACK_POS[\"KW\"])\n",
    "    CO_COL  = resolve_col(df, PREF_CO,  FALLBACK_POS[\"CO\"])\n",
    "    DT_COL  = resolve_col(df, PREF_DT,  FALLBACK_POS[\"DT\"])\n",
    "    URL_COL = None\n",
    "    try:\n",
    "        URL_COL = resolve_col(df, PREF_URL, FALLBACK_POS[\"URL\"])\n",
    "    except KeyError:\n",
    "        pass  # URL 없으면 None\n",
    "\n",
    "    # 3) 날짜 파싱\n",
    "    work = df.copy()\n",
    "    work[\"__date\"] = pd.to_datetime(\n",
    "        work[DT_COL].astype(str).str.strip(),\n",
    "        format=\"%Y%m%d\",\n",
    "        errors=\"coerce\"\n",
    "    )\n",
    "\n",
    "    # 4) 완전 중복 제거: (키워드, 회사, 날짜[, URL]) 동일 시 1건만\n",
    "    subset = [KW_COL, CO_COL, \"__date\"]\n",
    "    if URL_COL and (URL_COL in work.columns):\n",
    "        subset.append(URL_COL)\n",
    "    work = work.drop_duplicates(subset=subset, keep=\"first\")\n",
    "\n",
    "    # 5) 월(MM) 기준으로 (키워드, 회사)당 월 1건 선택 (그 달 '가장 이른' 기사)\n",
    "    work[\"__ym\"] = work[\"__date\"].dt.to_period(\"M\")\n",
    "    picked_idx = []\n",
    "    for (_, _, ym), g in work.dropna(subset=[\"__date\", \"__ym\"]).groupby([KW_COL, CO_COL, \"__ym\"]):\n",
    "        idx = g[\"__date\"].idxmin()   # 최신을 원하면 idxmax()로 변경\n",
    "        picked_idx.append(idx)\n",
    "\n",
    "    out = (work.loc[picked_idx]\n",
    "           .sort_values([KW_COL, CO_COL, \"__date\"])\n",
    "           .drop(columns=[\"__date\", \"__ym\"])\n",
    "           .reset_index(drop=True))\n",
    "\n",
    "    # 6) 저장 (행 많으면 monthly_one_2, _3 ... 로 분할)\n",
    "    write_split(out, OUT_PATH, BASE_SHEET)\n",
    "    print(f\"[월 1건] 사용시트={sheets}  입력={len(work)}  출력={len(out)} → {OUT_PATH}\")\n",
    "    print(f\"해석된 컬럼명: KW='{KW_COL}', CO='{CO_COL}', DT='{DT_COL}', URL='{URL_COL}'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55323868",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
